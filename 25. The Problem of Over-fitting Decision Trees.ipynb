{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5soGuirloNgq"
   },
   "source": [
    "![Astrofisica Computacional](../logo.PNG)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 25. El problema del sobre-ajuste de los Árboles de Decisión.\n",
    "\n",
    "\n",
    "Eduard Larrañaga (ealarranaga@unal.edu.co)\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Ff4KTapaoNgx"
   },
   "source": [
    "### Resumen\n",
    "\n",
    "En este cuaderno se ilustrará el problema del sobre-ajuste de los árboles de decisión.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Y85Y_aIb8meo"
   },
   "source": [
    "El sobre-ajuste de datos hace referencia a que un algoritmo intenta incorporar todos los puntos del conjunto de datos (incluso los más aislados). Esto puede tener como consecuencia que se pierde el poder de predicción general. \n",
    "\n",
    "\n",
    "En este cuaderno ilustraremos estos inconvenientes en el algoritmo de árbol de decisión cuando su entrenamiento no se supervisa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "cn0RkhCyHfEO"
   },
   "source": [
    "### Cargando los datos\n",
    "\n",
    "De nuevo utilizaremos el archivo `'sdss_galaxy_colors.npy'`con los datos fotométricos de las galaxias. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "z2_uSWSg5VRk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([(19.84132, 19.52656, 19.46946, 19.17955, 19.10763, b'QSO', 0.539301  , 6.543622e-05),\n",
       "       (19.86318, 18.66298, 17.84272, 17.38978, 17.14313, b'GALAXY', 0.1645703 , 1.186625e-05),\n",
       "       (19.97362, 18.31421, 17.47922, 17.0744 , 16.76174, b'GALAXY', 0.04190006, 2.183788e-05),\n",
       "       ...,\n",
       "       (19.82667, 18.10038, 17.16133, 16.5796 , 16.19755, b'GALAXY', 0.0784592 , 2.159406e-05),\n",
       "       (19.98672, 19.75385, 19.5713 , 19.27739, 19.25895, b'QSO', 1.567295  , 4.505933e-04),\n",
       "       (18.00024, 17.80957, 17.77302, 17.72663, 17.7264 , b'QSO', 0.4749449 , 6.203324e-05)],\n",
       "      dtype=[('u', '<f8'), ('g', '<f8'), ('r', '<f8'), ('i', '<f8'), ('z', '<f8'), ('spec_class', 'S6'), ('redshift', '<f8'), ('redshift_err', '<f8')])"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "data = np.load('sdss_galaxy_colors.npy')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C7pkVeizIyj5"
   },
   "source": [
    "Las características incorporados en el conjunto de datos son:\n",
    "\n",
    "| dtype | Feature|\n",
    "|:-:|:-:|\n",
    "|`u` |u band filter|\n",
    "|`g` |g band filter|\n",
    "|`r` |r band filter|\n",
    "|`i` |i band filter|\n",
    "|`z` |z band filter|\n",
    "|`spec_class` |spectral class|\n",
    "|`redshift` |redshift|\n",
    "|`redshift_err` |redshift error|\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ca9ZEeaNK8Vh"
   },
   "source": [
    "El número de galaxias en el conjunto es"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 536,
     "status": "ok",
     "timestamp": 1612142762690,
     "user": {
      "displayName": "Eduard Alexis Larranaga",
      "photoUrl": "https://lh3.googleusercontent.com/a-/AOh14GgCVABzEgj-rCdyxWa29RnA0kIYUCXAaVbnRYOEhQ=s64",
      "userId": "04402438389940282602"
     },
     "user_tz": 300
    },
    "id": "8JHyXtPlK6Hs",
    "outputId": "12892e14-8457-4cd4-d2a9-4befaa94a8c6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 16,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = data.size\n",
    "n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "geu4TFRioNgx"
   },
   "source": [
    "---\n",
    "### Entrenamiento del Árbol de Decisión\n",
    "\n",
    "Como se vió en la práctica anterior, los árboles de decisión tienen ventajas como\n",
    "\n",
    "- Son fáciles de implementar \n",
    "- Son fáciles de interpretar\n",
    "- Los datos no requieren mucha preparación \n",
    "- Usualmente los árboles de decisión son eficientes computacionalmente.\n",
    "\n",
    "Sin embargo, los árboles de decisión también tienen limitaciones. La mayor de ellas es que tienden a sobre-ajustar los datos si no se supervisa el proceso de entrenamiento. Con el sobre-ajuste, se intentará crear un árbol supercomplicado que intenta dar cuenta de todos los datos de entrada. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "675UL8zdLlbc"
   },
   "source": [
    "El primer paso para el entrenamiento del árbol es definir los conjuntos de entrada 'features' y 'targets'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Q53oIok9eCgL"
   },
   "outputs": [],
   "source": [
    "# Function returning the 4 color indices and the redshifts\n",
    "\n",
    "features, targets = ...\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3DjjbFANBHcD"
   },
   "source": [
    "Luego, deben dividirse estos arreglos en los subconjuntos de entrenamiento y prueba. Puede escogerse una división de (50:50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JTULQCiYZ8U-"
   },
   "outputs": [],
   "source": [
    "split_n = n//2\n",
    "train_features = features[:split]\n",
    "test_features = features[split:]\n",
    "train_targets = ...\n",
    "trest_targets = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FNehsBLLFWUH"
   },
   "source": [
    "Ahora se utilizara de nuevo la función `sklearn.tree.DecisionTreeRegressor`. Sin embargo, en esta ocasión se utilizará el argumento **tree depth** para reducir el sobre-ajuste. Este argumento restringe el número de nodos en el árbol. Incialmente, definiremos una profundidad máxima de 5,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mG9255X6fcdH"
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "dec_tree = DecisionTreeRegressor(max_depth=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "twCZM4TefbG5"
   },
   "source": [
    "\n",
    "Utilizando el método `.fit()` se entrenará el algoritmo utilizando los subconjuntos correspondiente.\n",
    "\n",
    "Información detallada de los árboles de decisión se puede encontrar en \n",
    "\n",
    "https://scikit-learn.org/stable/auto_examples/tree/plot_tree_regression.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DcJwQ_8bgmdW"
   },
   "outputs": [],
   "source": [
    "dec_tree.fit(train_features, train_targets)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "C4-CuGQ2YDt6"
   },
   "source": [
    "#### Prueba del Árbol de Decisión\n",
    "\n",
    "Una vez que se construye en árbol de decisión, se aplicará el método `.predict()` sobre el conjunto de prueba,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hV_1GWdc6GL6"
   },
   "outputs": [],
   "source": [
    "predictions = dec_tree.predict(test_features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OniL8coCYm9-"
   },
   "source": [
    "Al igual que se hizo anteriormente, se utilizará la mediana delos residuos para medir la precisión del algoritmo,\n",
    "\n",
    "\\begin{equation}\n",
    "\\text{eval_dec_tree} = \\text{median}\\left\\lbrace \\left| \\text{predictions}_i - \\text{targets}_i \\right|\\right\\rbrace\n",
    "\\end{equation}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SDLt8C-IZJUG"
   },
   "outputs": [],
   "source": [
    "eval_dec_tree = ..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DGdRXf17ZwKD"
   },
   "source": [
    "#### Sobre-Ajuste y Profundidad del Árbol \n",
    "\n",
    "Para observar el sobre-ajuste de los datos, se examinará el papel de la profundidad del árbol en la precisión del ajuste. Se podría esperar que a mayor profundidad, mejor sería la precisión. Sin embargo, una mayor profundidad resultará en un sobre-ajuste de los datos de entrenamiento que a su vez implicará una menor precisión en la predicción del algoritmo.\n",
    "\n",
    "**1. Defina una función que cree el árbol de decisión  con profundidades en el rango de 0 a 40.La función debe predecir el corrimiento al rojo de los conjuntos de entrenamiento y de prueba y calcular la mediana de los residuos para evaluar el algoritmo.**\n",
    "\n",
    "**2. Grafique la mediana de los residuos vs profundidad del árbol.**\n",
    "\n",
    "El gráfico debe lucir como este:\n",
    "\n",
    "<center>\n",
    "<img src=\"https://groklearning-cdn.com/problems/8Cet6iLGMbP2L8t7SVkEEg/overfitting.png\" width=450>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nUY7ZcLrAQOT"
   },
   "source": [
    "Este gráfico muestra como la precisión sobre el conjunto de entrenamiento mejora con la profundidad. En efecto,  **para profundidades superiores a 27, el error es cero!**\n",
    "\n",
    "Sin embargo, la predicción sobre el conjunto de prueba mejora inicialmente, pero luego empeora para grandes profundidades. Como se puede observar de la figura, para profundidades mayores que 19, el arbol de decisión comienza a presentar un sobre-ajuste de los datos de entrenamiento que se manifiesta como un aumento en el error de las predicciones en el conjunto de prueba. \n",
    "\n",
    "De acuerdo con esta información, para el conjunto de datos de galaxias es posible prevenir el sobre-ajuste al utilziar una profundidad máxima alrededor de 19 o 20."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "02. The Problem of Over-fitting Decision Trees.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
